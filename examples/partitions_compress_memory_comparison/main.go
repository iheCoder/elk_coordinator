package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"runtime"
	"strconv"
	"strings"
	"time"

	"github.com/iheCoder/elk_coordinator/data"
	"github.com/iheCoder/elk_coordinator/model"
	"github.com/iheCoder/elk_coordinator/partition"
	"github.com/redis/go-redis/v9"
)

const (
	PARTITION_COUNT = 50000
)

func main() {
	// è¿æ¥åˆ°æœ¬åœ°Redis
	redisClient := redis.NewClient(&redis.Options{
		Addr:     "localhost:6379",
		Password: "",
		DB:       0,
	})

	// æµ‹è¯•è¿æ¥
	ctx := context.Background()
	if err := redisClient.Ping(ctx).Err(); err != nil {
		log.Fatalf("æ— æ³•è¿æ¥åˆ°Redis: %v\nè¯·ç¡®ä¿RedisæœåŠ¡æ­£åœ¨è¿è¡Œ (localhost:6379)", err)
	}

	fmt.Printf("=== Rediså†…å­˜ä½¿ç”¨é‡æ¯”è¾ƒæµ‹è¯• ===\n")
	fmt.Printf("åˆ†åŒºæ•°é‡: %d\n", PARTITION_COUNT)
	fmt.Printf("å¼€å§‹æ—¶é—´: %s\n\n", time.Now().Format("2006-01-02 15:04:05"))

	// æ¸…ç†æ‰€æœ‰æµ‹è¯•é”®
	cleanupTestKeys(ctx, redisClient)

	// é¢„ç”Ÿæˆç»Ÿä¸€çš„åˆ†åŒºæ•°æ®é›†ï¼Œç¡®ä¿ä¸¤ä¸ªæµ‹è¯•ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ•°æ®
	fmt.Println("ğŸ”„ é¢„ç”Ÿæˆåˆ†åŒºæ•°æ®é›†...")
	partitions := generatePartitionDataset()
	fmt.Printf("âœ“ å·²ç”Ÿæˆ %d ä¸ªåˆ†åŒºæ•°æ®\n\n", len(partitions))

	// æµ‹è¯•1: æœªå‹ç¼©å­˜å‚¨
	fmt.Println("==== æµ‹è¯•1: æœªå‹ç¼©JSONå­˜å‚¨ ====")
	uncompressedSize := testUncompressedStorage(ctx, redisClient, partitions)
	time.Sleep(1 * time.Second)
	uncompressedMemory := getTestKeysMemoryUsage(ctx, redisClient, "test_uncompressed:")
	cleanupTestKeys(ctx, redisClient)
	runtime.GC()
	time.Sleep(1 * time.Second)

	// æµ‹è¯•2: å‹ç¼©å­˜å‚¨
	fmt.Println("\n==== æµ‹è¯•2: å‹ç¼©å­˜å‚¨ ====")
	// å…ˆæ³¨å†Œæ‰€æœ‰WorkerIDä»¥æ”¯æŒå‹ç¼©
	registerWorkersForCompression(ctx, redisClient, partitions)
	compressedSize := testCompressedStorage(ctx, redisClient, partitions)
	time.Sleep(1 * time.Second)
	compressedMemory := getTestKeysMemoryUsage(ctx, redisClient, "test_compressed:")
	cleanupTestKeys(ctx, redisClient)

	// è¾“å‡ºç»“æœ
	printResults(uncompressedSize, compressedSize, uncompressedMemory, compressedMemory)
}

func testUncompressedStorage(ctx context.Context, redisClient *redis.Client, partitions []*model.PartitionInfo) int64 {
	opts := data.DefaultOptions()
	opts.KeyPrefix = "test_uncompressed:"
	store := data.NewRedisDataStore(redisClient, opts)

	fmt.Printf("å­˜å‚¨ %d ä¸ªåˆ†åŒºï¼ˆæœªå‹ç¼©JSONæ ¼å¼ï¼‰...\n", len(partitions))

	var totalSize int64
	partitionsKey := "elk_active_partitions"

	for i, partition := range partitions {
		jsonData, err := json.Marshal(partition)
		if err != nil {
			log.Fatalf("åºåˆ—åŒ–åˆ†åŒºå¤±è´¥: %v", err)
		}

		err = store.HSetPartition(ctx, partitionsKey, strconv.Itoa(partition.PartitionID), string(jsonData))
		if err != nil {
			log.Fatalf("å­˜å‚¨åˆ†åŒºå¤±è´¥: %v", err)
		}

		totalSize += int64(len(jsonData))

		if (i+1)%10000 == 0 {
			fmt.Printf("å·²å­˜å‚¨ %d ä¸ªåˆ†åŒº\n", i+1)
		}
	}

	fmt.Printf("âœ“ æœªå‹ç¼©å­˜å‚¨å®Œæˆï¼Œæ€»æ•°æ®å¤§å°: %.2f MB\n", float64(totalSize)/1024/1024)
	return totalSize
}

func testCompressedStorage(ctx context.Context, redisClient *redis.Client, partitions []*model.PartitionInfo) int64 {
	opts := data.DefaultOptions()
	opts.KeyPrefix = "test_compressed:"
	store := data.NewRedisDataStore(redisClient, opts)

	compressor, err := partition.NewPartitionCompressor(store)
	if err != nil {
		log.Fatalf("åˆ›å»ºå‹ç¼©å™¨å¤±è´¥: %v", err)
	}

	fmt.Printf("å­˜å‚¨ %d ä¸ªåˆ†åŒºï¼ˆå‹ç¼©æ ¼å¼ï¼‰...\n", len(partitions))

	var totalSize int64
	compressedKey := "elk_compressed_archive"

	// ä¸€æ¬¡æ€§å‹ç¼©æ‰€æœ‰åˆ†åŒº
	fmt.Printf("æ­£åœ¨å‹ç¼©æ‰€æœ‰ %d ä¸ªåˆ†åŒº...\n", len(partitions))
	compressedBatch, err := compressor.CompressPartitionBatch(partitions)
	if err != nil {
		log.Fatalf("å‹ç¼©æ‰€æœ‰åˆ†åŒºå¤±è´¥: %v", err)
	}

	// åºåˆ—åŒ–å‹ç¼©æ‰¹æ¬¡
	batchJson, err := json.Marshal(compressedBatch)
	if err != nil {
		log.Fatalf("åºåˆ—åŒ–å‹ç¼©æ‰¹æ¬¡å¤±è´¥: %v", err)
	}

	// å­˜å‚¨åˆ°Redis
	batchKey := fmt.Sprintf("batch_all_%d", len(partitions))
	err = store.HSetPartition(ctx, compressedKey, batchKey, string(batchJson))
	if err != nil {
		log.Fatalf("å­˜å‚¨å‹ç¼©æ‰¹æ¬¡å¤±è´¥: %v", err)
	}

	totalSize = int64(len(batchJson))

	fmt.Printf("âœ“ å‹ç¼©å­˜å‚¨å®Œæˆï¼Œæ€»æ•°æ®å¤§å°: %.2f MB (1ä¸ªæ‰¹æ¬¡)\n", float64(totalSize)/1024/1024)
	return totalSize
}

// generatePartitionDataset é¢„ç”Ÿæˆç»Ÿä¸€çš„åˆ†åŒºæ•°æ®é›†ï¼Œç¡®ä¿ä¸¤æ¬¡æµ‹è¯•ä½¿ç”¨ç›¸åŒæ•°æ®
func generatePartitionDataset() []*model.PartitionInfo {
	partitions := make([]*model.PartitionInfo, PARTITION_COUNT)

	// ç”Ÿæˆ50ç§ä¸åŒçš„WorkerIDæ¨¡å¼ï¼Œæ›´ç¬¦åˆå®é™…æƒ…å†µ
	workerIDTemplates := make([]string, 50)
	for i := 0; i < 50; i++ {
		switch i % 5 {
		case 0:
			workerIDTemplates[i] = fmt.Sprintf("elk-coordinator-worker-5d4d557bdc-j4xvf-%d-08f3e2fa", i+1)
		case 1:
			workerIDTemplates[i] = fmt.Sprintf("elk-worker-deployment-%d-abc123def", i+1)
		case 2:
			workerIDTemplates[i] = fmt.Sprintf("coordinator-pod-%d-xyz789", i+1)
		case 3:
			workerIDTemplates[i] = fmt.Sprintf("worker-node-%d-mno456pqr", i+1)
		case 4:
			workerIDTemplates[i] = fmt.Sprintf("elk-processor-%d-stu123vwx", i+1)
		}
	}

	baseTime := time.Now()

	for i := 0; i < PARTITION_COUNT; i++ {
		partitionID := i + 1

		// 99.5%çš„åˆ†åŒºä¸ºStatusCompletedï¼Œ0.5%ä¸ºå¤±è´¥çŠ¶æ€ï¼ˆæ›´ç¬¦åˆå®é™…æƒ…å†µï¼‰
		var status model.PartitionStatus
		var errorMsg string

		if partitionID%200 == 0 { // 0.5%å¤±è´¥ç‡
			status = model.StatusFailed
			errorMsg = fmt.Sprintf("ç½‘ç»œè¶…æ—¶ï¼šåˆ†åŒº %d å¤„ç†å¤±è´¥", partitionID)
		} else {
			status = model.StatusCompleted
			errorMsg = ""
		}

		partitions[i] = &model.PartitionInfo{
			PartitionID:   partitionID,
			MinID:         int64((partitionID-1)*1000 + 1),
			MaxID:         int64(partitionID * 1000),
			WorkerID:      workerIDTemplates[partitionID%50], // ä½¿ç”¨50ç§ä¸åŒçš„WorkerID
			LastHeartbeat: time.Time{},                       // å®Œæˆçš„åˆ†åŒºé€šå¸¸æ²¡æœ‰å¿ƒè·³
			Status:        status,
			UpdatedAt:     baseTime.Add(-time.Duration(partitionID%86400) * time.Second),
			Version:       int64(partitionID%5 + 1), // ç‰ˆæœ¬1-5
			Error:         errorMsg,
			CreatedAt:     baseTime.Add(-time.Duration(partitionID) * time.Minute),
		}
	}

	return partitions
}

// getTestKeysMemoryUsage è·å–æµ‹è¯•ç›¸å…³keyçš„å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰
func getTestKeysMemoryUsage(ctx context.Context, redisClient *redis.Client, keyPrefix string) int64 {
	// è·å–æ‰€æœ‰æµ‹è¯•ç›¸å…³çš„key
	pattern := keyPrefix + "*"
	keys, err := redisClient.Keys(ctx, pattern).Result()
	if err != nil {
		log.Printf("è·å–keyåˆ—è¡¨å¤±è´¥: %v", err)
		return 0
	}

	var totalMemory int64
	for _, key := range keys {
		// ä½¿ç”¨MEMORY USAGEå‘½ä»¤è·å–æ¯ä¸ªkeyçš„å†…å­˜ä½¿ç”¨é‡
		memUsage, err := redisClient.MemoryUsage(ctx, key).Result()
		if err != nil {
			log.Printf("è·å–key %s å†…å­˜ä½¿ç”¨å¤±è´¥: %v", key, err)
			continue
		}
		totalMemory += memUsage
	}

	return totalMemory
}

func cleanupTestKeys(ctx context.Context, redisClient *redis.Client) {
	patterns := []string{
		"test_uncompressed:*",
		"test_compressed:*",
	}

	for _, pattern := range patterns {
		keys, err := redisClient.Keys(ctx, pattern).Result()
		if err != nil {
			continue
		}

		if len(keys) > 0 {
			redisClient.Del(ctx, keys...)
		}
	}

	runtime.GC()
	time.Sleep(100 * time.Millisecond)
}

func printResults(uncompressedSize, compressedSize, uncompressedMemory, compressedMemory int64) {
	fmt.Printf("\n" + strings.Repeat("=", 60) + "\n")
	fmt.Printf("           è¯¦ç»†æ€§èƒ½æ¯”è¾ƒç»“æœ\n")
	fmt.Printf(strings.Repeat("=", 60) + "\n")

	compressionRatio := float64(uncompressedSize) / float64(compressedSize)
	spaceSavingPercent := (1.0 - float64(compressedSize)/float64(uncompressedSize)) * 100

	uncompressedMB := float64(uncompressedSize) / 1024 / 1024
	compressedMB := float64(compressedSize) / 1024 / 1024

	fmt.Printf("\nğŸ“Š æ•°æ®å¤§å°å¯¹æ¯”:\n")
	fmt.Printf("â€¢ æœªå‹ç¼©JSONå­˜å‚¨: %.2f MB (å¹³å‡ %.1f bytes/åˆ†åŒº)\n",
		uncompressedMB, float64(uncompressedSize)/PARTITION_COUNT)
	fmt.Printf("â€¢ å‹ç¼©å­˜å‚¨:       %.2f MB (å¹³å‡ %.1f bytes/åˆ†åŒº)\n",
		compressedMB, float64(compressedSize)/PARTITION_COUNT)
	fmt.Printf("â€¢ å‹ç¼©æ¯”:         %.1f:1\n", compressionRatio)

	fmt.Printf("\nğŸ’¾ ç©ºé—´èŠ‚çœ:\n")
	fmt.Printf("â€¢ èŠ‚çœç©ºé—´: %.2f MB\n", uncompressedMB-compressedMB)
	fmt.Printf("â€¢ èŠ‚çœæ¯”ä¾‹: %.1f%%\n", spaceSavingPercent)

	fmt.Printf("\nğŸ—„ï¸  Rediså®é™…å†…å­˜ä½¿ç”¨:\n")
	uncompressedMemoryMB := float64(uncompressedMemory) / 1024 / 1024
	compressedMemoryMB := float64(compressedMemory) / 1024 / 1024
	memorySpaceSavingPercent := (1.0 - float64(compressedMemory)/float64(uncompressedMemory)) * 100

	fmt.Printf("â€¢ æœªå‹ç¼©æ–¹æ¡ˆ: %.2f MB\n", uncompressedMemoryMB)
	fmt.Printf("â€¢ å‹ç¼©æ–¹æ¡ˆ:   %.2f MB\n", compressedMemoryMB)
	fmt.Printf("â€¢ å†…å­˜èŠ‚çœ:   %.2f MB (%.1f%%)\n", uncompressedMemoryMB-compressedMemoryMB, memorySpaceSavingPercent)

	fmt.Printf("\nğŸ“ˆ æ‰©å±•åˆ†æ - ä¸åŒè§„æ¨¡çš„é¢„ä¼°å†…å­˜ä½¿ç”¨:\n")
	fmt.Printf("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
	fmt.Printf("â”‚   åˆ†åŒºæ•°é‡  â”‚  æœªå‹ç¼©å†…å­˜ â”‚  å‹ç¼©å†…å­˜   â”‚   èŠ‚çœå†…å­˜  â”‚\n")
	fmt.Printf("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n")

	avgUncompressed := float64(uncompressedSize) / PARTITION_COUNT
	avgCompressed := float64(compressedSize) / PARTITION_COUNT

	partitionCounts := []int{100000, 500000, 1000000, 5000000, 10000000}
	for _, count := range partitionCounts {
		uncompressedProj := float64(count) * avgUncompressed / 1024 / 1024
		compressedProj := float64(count) * avgCompressed / 1024 / 1024
		saved := uncompressedProj - compressedProj

		fmt.Printf("â”‚ %7s     â”‚ %8.1f MB â”‚ %8.1f MB â”‚ %8.1f MB â”‚\n",
			formatNumber(count), uncompressedProj, compressedProj, saved)
	}
	fmt.Printf("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")

	fmt.Printf("\nğŸ¯ æ€»ç»“:\n")
	fmt.Printf("âœ“ å‹ç¼©æ–¹æ¡ˆèŠ‚çœ %.1f%% å­˜å‚¨ç©ºé—´ï¼Œå‹ç¼©æ¯” %.1f:1\n", spaceSavingPercent, compressionRatio)
	fmt.Printf("âœ“ Rediså†…å­˜å®é™…èŠ‚çœ %.1f%% (%.2f MB)\n", memorySpaceSavingPercent, uncompressedMemoryMB-compressedMemoryMB)
	fmt.Printf("âœ“ å¯¹äºå¤§è§„æ¨¡åˆ†åŒºåœºæ™¯ï¼Œå†…å­˜èŠ‚çœæ•ˆæœæ˜¾è‘—\n")
	fmt.Printf("âœ“ å»ºè®®åœ¨å®Œæˆåˆ†åŒºè¶…è¿‡10ä¸‡æ—¶ä½¿ç”¨å‹ç¼©å­˜å‚¨\n")
}

func formatNumber(n int) string {
	if n >= 1000000 {
		return fmt.Sprintf("%.1fM", float64(n)/1000000)
	}
	if n >= 1000 {
		return fmt.Sprintf("%.1fK", float64(n)/1000)
	}
	return fmt.Sprintf("%d", n)
}

// registerWorkersForCompression æ³¨å†Œæ‰€æœ‰å”¯ä¸€çš„WorkerIDä»¥æ”¯æŒå‹ç¼©æ˜ å°„
func registerWorkersForCompression(ctx context.Context, redisClient *redis.Client, partitions []*model.PartitionInfo) {
	opts := data.DefaultOptions()
	opts.KeyPrefix = "test_compressed:"
	store := data.NewRedisDataStore(redisClient, opts)

	// æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„WorkerID
	workerIDSet := make(map[string]bool)
	for _, partition := range partitions {
		workerIDSet[partition.WorkerID] = true
	}

	fmt.Printf("ğŸ”§ æ³¨å†Œ %d ä¸ªå”¯ä¸€WorkerIDä»¥æ”¯æŒå‹ç¼©æ˜ å°„...\n", len(workerIDSet))

	// æ³¨å†Œæ‰€æœ‰WorkerID
	for workerID := range workerIDSet {
		err := store.RegisterWorker(ctx, workerID)
		if err != nil {
			log.Printf("æ³¨å†ŒWorkerID %s å¤±è´¥: %v", workerID, err)
		}
	}

	fmt.Printf("âœ“ WorkerIDæ³¨å†Œå®Œæˆ\n")
}
